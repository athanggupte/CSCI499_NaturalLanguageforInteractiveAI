Logger configured successfully
Args:
	output_dir = outputs
	data_dir = books
	downstream_eval = False
	vocab_size = 3000
	batch_size = 1024
	force_cpu = False
	analogies_fn = analogies_v3000_1309.json
	word_vector_fn = learned_word_vectors.txt
	num_epochs = 21
	val_every = 5
	save_every = 5
	learning_rate = 0.01
	model = skipgram
	embedding_dim = 300
	context_len = 4
	no_pad = False
Total examples : 2916933
Total memory : 189.16 MiB
Total examples : 835336
Total memory : 54.17 MiB
SkipGramModel(
  (embed): Embedding(3000, 300)
  (linear): Linear(in_features=300, out_features=3000, bias=True)
)
Epoch 0
train loss : 0.013284341308914933 | train acc: 0.16505557490029005
val loss : 0.012037514753447956 | val acc: 0.1706217266052171
saving word vec to outputs/learned_word_vectors.txt
Loading vectors from file 'outputs/learned_word_vectors.txt'...
... done loading vectors
Evaluating downstream performance on analogy task over 1309 analogies...
WARNING: KeyError: "Key 'ministers' not present in vocabulary"
...Total performance across all 1309 analogies: 0.0000 (Exact); 0.0020 (MRR); 489 (MR)
...Analogy performance across 969 "sem" relation types: 0.0000 (Exact); 0.0020 (MRR); 493 (MR)
+---------------+-----+--------+--------+------+
|    relation   |  N  | exact  |  MRR   |  MR  |
+---------------+-----+--------+--------+------+
|    capitals   |  1  | 0.0000 | 0.0022 | 458  |
| binary_gender |  12 | 0.0000 | 0.0012 | 839  |
|    antonym    |  54 | 0.0000 | 0.0023 | 429  |
|     member    |  4  | 0.0000 | 0.0004 | 2396 |
|   hypernomy   | 542 | 0.0000 | 0.0018 | 558  |
|    similar    | 117 | 0.0000 | 0.0040 | 248  |
|     partof    |  29 | 0.0000 | 0.0024 | 419  |
|   instanceof  |  9  | 0.0000 | 0.0003 | 3250 |
|  derivedfrom  | 133 | 0.0000 | 0.0010 | 1004 |
|   hascontext  |  32 | 0.0000 | 0.0045 | 221  |
|   relatedto   |  10 | 0.0000 | 0.0010 | 956  |
|  attributeof  |  11 | 0.0000 | 0.0009 | 1128 |
|     causes    |  6  | 0.0000 | 0.0012 | 822  |
|    entails    |  9  | 0.0000 | 0.0006 | 1559 |
+---------------+-----+--------+--------+------+
...Analogy performance across 340 "syn" relation types: 0.0000 (Exact); 0.0021 (MRR); 478 (MR)
+--------------------+-----+--------+--------+-----+
|      relation      |  N  | exact  |  MRR   |  MR |
+--------------------+-----+--------+--------+-----+
|      adj_adv       |  22 | 0.0000 | 0.0057 | 176 |
|    comparative     |  7  | 0.0000 | 0.0020 | 499 |
|    superlative     |  3  | 0.0000 | 0.0027 | 370 |
| present_participle |  62 | 0.0000 | 0.0013 | 749 |
|      denonym       |  2  | 0.0000 | 0.0000 | inf |
|     past_tense     |  64 | 0.0000 | 0.0018 | 549 |
|    plural_nouns    | 107 | 0.0000 | 0.0027 | 376 |
|    plural_verbs    |  73 | 0.0000 | 0.0011 | 913 |
+--------------------+-----+--------+--------+-----+
saving model to outputs/model.ckpt
Epoch 1
train loss : 0.010259211766208294 | train acc: 0.16864606911574911
Epoch 2
train loss : 0.010175622871198563 | train acc: 0.170582477239555
Epoch 3
train loss : 0.010107946724337668 | train acc: 0.17167862817904317
Epoch 4
train loss : 0.01006045361909533 | train acc: 0.17217302208429006
Epoch 5
train loss : 0.010030960765817304 | train acc: 0.17245736070695364
val loss : 0.012617928143727648 | val acc: 0.1752449884465624
saving word vec to outputs/learned_word_vectors.txt
Loading vectors from file 'outputs/learned_word_vectors.txt'...
... done loading vectors
Evaluating downstream performance on analogy task over 1309 analogies...
WARNING: KeyError: "Key 'ministers' not present in vocabulary"
...Total performance across all 1309 analogies: 0.0344 (Exact); 0.0604 (MRR); 17 (MR)
...Analogy performance across 969 "sem" relation types: 0.0083 (Exact); 0.0208 (MRR); 48 (MR)
+---------------+-----+--------+--------+-----+
|    relation   |  N  | exact  |  MRR   |  MR |
+---------------+-----+--------+--------+-----+
|    capitals   |  1  | 1.0000 | 1.0000 |  1  |
| binary_gender |  12 | 0.2500 | 0.4266 |  2  |
|    antonym    |  54 | 0.0185 | 0.0417 |  23 |
|     member    |  4  | 0.0000 | 0.0331 |  30 |
|   hypernomy   | 542 | 0.0000 | 0.0095 | 104 |
|    similar    | 117 | 0.0085 | 0.0181 |  55 |
|     partof    |  29 | 0.0690 | 0.0866 |  11 |
|   instanceof  |  9  | 0.0000 | 0.0107 |  93 |
|  derivedfrom  | 133 | 0.0000 | 0.0060 | 167 |
|   hascontext  |  32 | 0.0000 | 0.0035 | 287 |
|   relatedto   |  10 | 0.0000 | 0.0015 | 669 |
|  attributeof  |  11 | 0.0000 | 0.0484 |  20 |
|     causes    |  6  | 0.0000 | 0.0015 | 688 |
|    entails    |  9  | 0.0000 | 0.0343 |  29 |
+---------------+-----+--------+--------+-----+
...Analogy performance across 340 "syn" relation types: 0.1088 (Exact); 0.1731 (MRR); 6 (MR)
+--------------------+-----+--------+--------+-----+
|      relation      |  N  | exact  |  MRR   |  MR |
+--------------------+-----+--------+--------+-----+
|      adj_adv       |  22 | 0.0000 | 0.0080 | 124 |
|    comparative     |  7  | 0.2857 | 0.3765 |  2  |
|    superlative     |  3  | 0.6667 | 0.6697 |  1  |
| present_participle |  62 | 0.0806 | 0.1367 |  7  |
|      denonym       |  2  | 0.5000 | 0.5041 |  1  |
|     past_tense     |  64 | 0.2188 | 0.3119 |  3  |
|    plural_nouns    | 107 | 0.0748 | 0.1423 |  7  |
|    plural_verbs    |  73 | 0.0685 | 0.1282 |  7  |
+--------------------+-----+--------+--------+-----+
saving model to outputs/model.ckpt
Epoch 6
train loss : 0.010014722113608373 | train acc: 0.1725651345029815
Epoch 7
train loss : 0.010006007832230162 | train acc: 0.17260194815197802
Epoch 8
train loss : 0.01000060740382358 | train acc: 0.17267597982387298
Epoch 9
train loss : 0.009997499165889798 | train acc: 0.1727371787300914
Epoch 10
train loss : 0.009995583688370197 | train acc: 0.17275453024588316
val loss : 0.012272631450483174 | val acc: 0.17540729822386555
saving word vec to outputs/learned_word_vectors.txt
Loading vectors from file 'outputs/learned_word_vectors.txt'...
... done loading vectors
Evaluating downstream performance on analogy task over 1309 analogies...
WARNING: KeyError: "Key 'ministers' not present in vocabulary"
...Total performance across all 1309 analogies: 0.0435 (Exact); 0.0726 (MRR); 14 (MR)
...Analogy performance across 969 "sem" relation types: 0.0124 (Exact); 0.0247 (MRR); 41 (MR)
+---------------+-----+--------+--------+------+
|    relation   |  N  | exact  |  MRR   |  MR  |
+---------------+-----+--------+--------+------+
|    capitals   |  1  | 1.0000 | 1.0000 |  1   |
| binary_gender |  12 | 0.3333 | 0.4579 |  2   |
|    antonym    |  54 | 0.0370 | 0.0724 |  13  |
|     member    |  4  | 0.0000 | 0.0149 |  67  |
|   hypernomy   | 542 | 0.0018 | 0.0100 |  99  |
|    similar    | 117 | 0.0171 | 0.0268 |  37  |
|     partof    |  29 | 0.0345 | 0.0513 |  19  |
|   instanceof  |  9  | 0.0000 | 0.0183 |  54  |
|  derivedfrom  | 133 | 0.0075 | 0.0137 |  73  |
|   hascontext  |  32 | 0.0000 | 0.0175 |  57  |
|   relatedto   |  10 | 0.0000 | 0.0005 | 2173 |
|  attributeof  |  11 | 0.0000 | 0.0124 |  80  |
|     causes    |  6  | 0.0000 | 0.0335 |  29  |
|    entails    |  9  | 0.0000 | 0.0562 |  17  |
+---------------+-----+--------+--------+------+
...Analogy performance across 340 "syn" relation types: 0.1324 (Exact); 0.2093 (MRR); 5 (MR)
+--------------------+-----+--------+--------+----+
|      relation      |  N  | exact  |  MRR   | MR |
+--------------------+-----+--------+--------+----+
|      adj_adv       |  22 | 0.0000 | 0.0127 | 78 |
|    comparative     |  7  | 0.2857 | 0.4295 | 2  |
|    superlative     |  3  | 0.0000 | 0.1991 | 5  |
| present_participle |  62 | 0.0968 | 0.1442 | 6  |
|      denonym       |  2  | 0.0000 | 0.0140 | 71 |
|     past_tense     |  64 | 0.2812 | 0.3917 | 2  |
|    plural_nouns    | 107 | 0.1121 | 0.1965 | 5  |
|    plural_verbs    |  73 | 0.0959 | 0.1673 | 5  |
+--------------------+-----+--------+--------+----+
saving model to outputs/model.ckpt
Epoch 11
train loss : 0.009993959147327508 | train acc: 0.1727616744296335
Epoch 12
train loss : 0.00999253001011759 | train acc: 0.17278203739585418
Epoch 13
train loss : 0.009991573475146972 | train acc: 0.17275820566688915
Epoch 14
train loss : 0.009990674959709452 | train acc: 0.17279864730484953
Epoch 15
train loss : 0.009989907475702907 | train acc: 0.17280055007291967
val loss : 0.012003712004561927 | val acc: 0.17542626691403346
saving word vec to outputs/learned_word_vectors.txt
Loading vectors from file 'outputs/learned_word_vectors.txt'...
... done loading vectors
Evaluating downstream performance on analogy task over 1309 analogies...
WARNING: KeyError: "Key 'ministers' not present in vocabulary"
...Total performance across all 1309 analogies: 0.0428 (Exact); 0.0752 (MRR); 13 (MR)
...Analogy performance across 969 "sem" relation types: 0.0103 (Exact); 0.0250 (MRR); 40 (MR)
+---------------+-----+--------+--------+-----+
|    relation   |  N  | exact  |  MRR   |  MR |
+---------------+-----+--------+--------+-----+
|    capitals   |  1  | 0.0000 | 0.2500 |  4  |
| binary_gender |  12 | 0.4167 | 0.5247 |  1  |
|    antonym    |  54 | 0.0741 | 0.1163 |  8  |
|     member    |  4  | 0.0000 | 0.0242 |  41 |
|   hypernomy   | 542 | 0.0018 | 0.0115 |  87 |
|    similar    | 117 | 0.0000 | 0.0079 | 125 |
|     partof    |  29 | 0.0000 | 0.0167 |  60 |
|   instanceof  |  9  | 0.0000 | 0.0250 |  39 |
|  derivedfrom  | 133 | 0.0000 | 0.0152 |  65 |
|   hascontext  |  32 | 0.0000 | 0.0142 |  70 |
|   relatedto   |  10 | 0.0000 | 0.0036 | 281 |
|  attributeof  |  11 | 0.0000 | 0.0578 |  17 |
|     causes    |  6  | 0.0000 | 0.0064 | 156 |
|    entails    |  9  | 0.0000 | 0.0308 |  32 |
+---------------+-----+--------+--------+-----+
...Analogy performance across 340 "syn" relation types: 0.1353 (Exact); 0.2182 (MRR); 5 (MR)
+--------------------+-----+--------+--------+----+
|      relation      |  N  | exact  |  MRR   | MR |
+--------------------+-----+--------+--------+----+
|      adj_adv       |  22 | 0.0455 | 0.0588 | 17 |
|    comparative     |  7  | 0.1429 | 0.2966 | 3  |
|    superlative     |  3  | 0.0000 | 0.0768 | 13 |
| present_participle |  62 | 0.1129 | 0.1954 | 5  |
|      denonym       |  2  | 0.5000 | 0.5013 | 1  |
|     past_tense     |  64 | 0.1562 | 0.2710 | 3  |
|    plural_nouns    | 107 | 0.1215 | 0.2054 | 4  |
|    plural_verbs    |  73 | 0.1781 | 0.2488 | 4  |
+--------------------+-----+--------+--------+----+
saving model to outputs/model.ckpt
Epoch 16
train loss : 0.009989193936815782 | train acc: 0.172796212799977
Epoch 17
train loss : 0.009988607445168846 | train acc: 0.1728235136084837
Epoch 18
train loss : 0.009988195971229822 | train acc: 0.1728035634307908
Epoch 19
train loss : 0.009987775649889785 | train acc: 0.17279280753554935
Epoch 20
train loss : 0.009987375508404147 | train acc: 0.17282712972944797
val loss : 0.011673682069122865 | val acc: 0.17550891503732044
saving word vec to outputs/learned_word_vectors.txt
Loading vectors from file 'outputs/learned_word_vectors.txt'...
... done loading vectors
Evaluating downstream performance on analogy task over 1309 analogies...
WARNING: KeyError: "Key 'ministers' not present in vocabulary"
...Total performance across all 1309 analogies: 0.0443 (Exact); 0.0712 (MRR); 14 (MR)
...Analogy performance across 969 "sem" relation types: 0.0134 (Exact); 0.0260 (MRR); 39 (MR)
+---------------+-----+--------+--------+-----+
|    relation   |  N  | exact  |  MRR   |  MR |
+---------------+-----+--------+--------+-----+
|    capitals   |  1  | 1.0000 | 1.0000 |  1  |
| binary_gender |  12 | 0.5000 | 0.5737 |  1  |
|    antonym    |  54 | 0.0556 | 0.0669 |  14 |
|     member    |  4  | 0.0000 | 0.0133 |  75 |
|   hypernomy   | 542 | 0.0037 | 0.0145 |  69 |
|    similar    | 117 | 0.0000 | 0.0140 |  71 |
|     partof    |  29 | 0.0345 | 0.0541 |  18 |
|   instanceof  |  9  | 0.0000 | 0.0263 |  38 |
|  derivedfrom  | 133 | 0.0000 | 0.0104 |  96 |
|   hascontext  |  32 | 0.0000 | 0.0096 | 104 |
|   relatedto   |  10 | 0.0000 | 0.0026 | 391 |
|  attributeof  |  11 | 0.0000 | 0.0158 |  63 |
|     causes    |  6  | 0.0000 | 0.0083 | 120 |
|    entails    |  9  | 0.0000 | 0.0436 |  22 |
+---------------+-----+--------+--------+-----+
...Analogy performance across 340 "syn" relation types: 0.1324 (Exact); 0.2001 (MRR); 5 (MR)
+--------------------+-----+--------+--------+-----+
|      relation      |  N  | exact  |  MRR   |  MR |
+--------------------+-----+--------+--------+-----+
|      adj_adv       |  22 | 0.0000 | 0.0137 |  73 |
|    comparative     |  7  | 0.2857 | 0.3439 |  2  |
|    superlative     |  3  | 0.0000 | 0.1425 |  7  |
| present_participle |  62 | 0.0806 | 0.1657 |  6  |
|      denonym       |  2  | 0.0000 | 0.0044 | 228 |
|     past_tense     |  64 | 0.2500 | 0.3473 |  2  |
|    plural_nouns    | 107 | 0.1402 | 0.1845 |  5  |
|    plural_verbs    |  73 | 0.0959 | 0.1731 |  5  |
+--------------------+-----+--------+--------+-----+
saving model to outputs/model.ckpt
